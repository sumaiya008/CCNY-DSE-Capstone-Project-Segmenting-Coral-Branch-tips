{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Al8RhdEEEC",
        "outputId": "c3e787ec-35ff-4f64-bf9f-56983e67ebb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pg9QMxj2DT5b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import gdown\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yNcD1FBRDT5d"
      },
      "outputs": [],
      "source": [
        "# with open('../data/external/data.pkl','rb') as f:\n",
        "#     X_train,y_train,X_test,y_test = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QriixTFCd-_",
        "outputId": "193fe168-18ff-468c-e5ab-e9cdccc74bdb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the updated shareable link\n",
        "# #file_url = 'https://drive.google.com/uc?id=1d76IaKEbiKGAwB1cMGh8FG9g-lI2d9Vf'\n",
        "\n",
        "# # Define the destination file path where the file will be downloaded\n",
        "# destination_path = '/content/drive/MyDrive/Capstone/Pickled/'\n",
        "\n",
        "# # Download the file from the updated shareable link\n",
        "# #gdown.download(file_url, destination_path, quiet=False)\n",
        "\n",
        "# # Load the pickled data\n",
        "# with open(destination_path+'data.pickle', 'rb') as f:\n",
        "#     X_train, y_train, X_test, y_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "9aGHqCt5Cm8D"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Capstone/Coral_images/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_kBtKrOGNeR",
        "outputId": "2db04a91-e5ff-4995-dbc6-a5d54c723e62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APAL  data_augmented.npz  Pseudodiploria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your image folders\n",
        "image_folder_path = \"/content/drive/MyDrive/Capstone/Coral_images/\"\n",
        "\n",
        "# Initialize lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through each folder in the main directory\n",
        "for folder_name in os.listdir(image_folder_path):\n",
        "    folder_path = os.path.join(image_folder_path, folder_name)\n",
        "\n",
        "    # Check if the item in the main directory is a folder\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Iterate through each image file in the subfolder\n",
        "        for image_filename in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, image_filename)\n",
        "\n",
        "            # Load the image using OpenCV\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Check if the image was loaded successfully\n",
        "            if image is not None:\n",
        "                # Resize the image to 1080x1080 if needed\n",
        "                if image.shape[0] >= 1080 and image.shape[1] >= 1080:\n",
        "                    image = cv2.resize(image, (1080, 1080))\n",
        "                else:\n",
        "                    print(f\"Image dimensions are too small for resizing: {image_path}\")\n",
        "\n",
        "                # Append the image to the list of images\n",
        "                images.append(image)\n",
        "\n",
        "                # Append the label (folder name) to the list of labels\n",
        "                labels.append(folder_name)\n",
        "            else:\n",
        "                # Handle the case where the image couldn't be loaded\n",
        "                print(f\"Error loading image: {image_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fViSclTlCm80",
        "outputId": "2594c016-7899-496b-e2a5-2689cdc01dcd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: /content/drive/MyDrive/Capstone/Coral_images/Pseudodiploria/.DS_Store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the lists to NumPy arrays for further analysis\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Now, check the shapes\n",
        "print(f\"Images shape: {images.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")"
      ],
      "metadata": {
        "id": "DvVaegV7uNBI",
        "outputId": "f59e9187-529b-4960-c917-d4181bee34be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: (907, 1080, 1080, 3)\n",
            "Labels shape: (907,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "K6sEsXG_uPPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfAV7nnmDT5d"
      },
      "outputs": [],
      "source": [
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X6EdmdVOuPh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfCGzVoNDT5e"
      },
      "outputs": [],
      "source": [
        "# Define the data augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6R7JG3BeeLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAkY71_FDT5e"
      },
      "outputs": [],
      "source": [
        "# Define the batch size for augmentation\n",
        "batch_size = 50 # adjust as needed\n",
        "\n",
        "# Apply data augmentation to the training set\n",
        "X_train_augmented = []\n",
        "y_train_augmented = []\n",
        "\n",
        "for i in range(X_train.shape[0]):\n",
        "    img = X_train[i]\n",
        "    label = y_train[i]\n",
        "\n",
        "    # Expand the dimensions of the image to (1, 1080, 1080, 3)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    for j in range(2):\n",
        "        x_augmented = datagen.flow(img, batch_size=1).next()\n",
        "        X_train_augmented.append(x_augmented[0])  # Extract the augmented image\n",
        "        y_train_augmented.append(label)\n",
        "    # Check if it's time to create a new batch\n",
        "    if len(X_train_augmented) >= batch_size:\n",
        "        X_train_augmented = np.array(X_train_augmented)\n",
        "        y_train_augmented = np.array(y_train_augmented)\n",
        "\n",
        "        #Clearing current batch\n",
        "        X_train_augmented = []\n",
        "        y_train_augmented = []\n",
        "\n",
        "# Convert any remaining data to NumPy arrays and train with the final batch\n",
        "if X_train_augmented:\n",
        "    X_train_augmented = np.array(X_train_augmented)\n",
        "    y_train_augmented = np.array(y_train_augmented)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrAcRXYBDT5e",
        "outputId": "d14a2b69-783e-4ae3-de10-a343e2c4f268"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# # Convert the augmented data to NumPy arrays\n",
        "# X_train_augmented = np.array(X_train_augmented)\n",
        "# y_train_augmented = np.array(y_train_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train_augmented shape: {X_train_augmented.shape}')\n",
        "print(f'y_train_augmented shape: {y_train_augmented.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Pb3-oHgTgEHR",
        "outputId": "cdcc103a-559b-4f73-9fe1-086e987ff1da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-dc6485079d8e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'X_train_augmented shape: {X_train_augmented.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'y_train_augmented shape: {y_train_augmented.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VEB8CpS6DT5e"
      },
      "outputs": [],
      "source": [
        "# Apply data augmentation to the test set\n",
        "X_test_augmented = []\n",
        "y_test_augmented = []\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    img = X_test[i]\n",
        "    label = y_test[i]\n",
        "\n",
        "    # Expand the dimensions of the image to (1, 1080, 1080, 3)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    for j in range(2):\n",
        "        x_augmented = datagen.flow(img, batch_size=1).next()\n",
        "        X_test_augmented.append(x_augmented[0])  # Extract the augmented image\n",
        "        y_test_augmented.append(label)\n",
        "    if len(X_test_augmented) >= batch_size:\n",
        "        X_test_augmented = np.array(X_test_augmented)\n",
        "        y_test_augmented = np.array(y_test_augmented)\n",
        "\n",
        "        X_test_augmented = []\n",
        "        y_test_augmented = []\n",
        "\n",
        "if X_test_augmented:\n",
        "    X_test_augmented = np.array(X_test_augmented)\n",
        "    y_test_augmented = np.array(y_test_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5Y7OIAx9DT5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873b3732-caad-4638-807e-6f2aa07b668a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test_augmented shape: (12, 1080, 1080, 3)\n",
            "y_test_augmented shape: (12,)\n"
          ]
        }
      ],
      "source": [
        "print(f'X_test_augmented shape: {X_test_augmented.shape}')\n",
        "print(f'y_test_augmented shape: {y_test_augmented.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvirTgJADT5e"
      },
      "outputs": [],
      "source": [
        "# print(f'X_train_augmented shape: {X_train_augmented.shape}')\n",
        "# print(f'y_train_augmented shape: {y_train_augmented.shape}')\n",
        "# print(f'X_test_augmented shape: {X_test_augmented.shape}')\n",
        "# print(f'y_test_augmented shape: {y_test_augmented.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YltwtP3EDT5f"
      },
      "outputs": [],
      "source": [
        "# Save the augmented data to files\n",
        "np.savez_compressed('/content/drive/MyDrive/Capstone/Coral_images/data_augmented.npz',\n",
        "                    X_train=X_train_augmented,\n",
        "                    y_train=y_train_augmented,\n",
        "                    X_test=X_test_augmented,\n",
        "                    y_test=y_test_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hxdBFgwYiM5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}