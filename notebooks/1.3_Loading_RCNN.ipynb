{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (1595, 224, 224, 3)\n",
      "Masks shape: (1595, 224, 224)\n",
      "Labels shape: (1595,)\n",
      "Class: APAL, Count: 812\n",
      "Class: Pseudodiploria, Count: 783\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define the paths to your image and annotation folders\n",
    "path_image = \"/Users/sumaiyauddin/Documents/Semester03/CCNY-DSE-Capstone-Project-Segmenting-Coral-Branch-tips/data/external/Coral_images/image\"\n",
    "path_annotations = \"/Users/sumaiyauddin/Documents/Semester03/CCNY-DSE-Capstone-Project-Segmenting-Coral-Branch-tips/data/external/Coral_images/annotation\"\n",
    "\n",
    "# Initialize lists to store images, labels, and masks\n",
    "images = []\n",
    "labels = []\n",
    "masks = []\n",
    "\n",
    "# Initialize counters for the classes\n",
    "apal_count = 0\n",
    "pseudodiploria_count = 0\n",
    "\n",
    "# Set the desired balance ratio\n",
    "desired_balance_ratio = 0.5  # 50% APAL, 50% Pseudodiploria\n",
    "\n",
    "# Initialize counters for oversampling APAL and undersampling Pseudodiploria\n",
    "oversample_apal = True\n",
    "undersample_pseudodiploria = False\n",
    "\n",
    "# Iterate through each image file in the image folder\n",
    "for image_filename in os.listdir(path_image):\n",
    "    if image_filename.lower().endswith(\".jpg\"):  # Check for image files\n",
    "        image_path = os.path.join(path_image, image_filename)\n",
    "\n",
    "        # Load the image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image was loaded successfully\n",
    "        if image is not None:\n",
    "            # Resize the image to 224x224 if needed\n",
    "            if image.shape[0] >= 224 and image.shape[1] >= 224:\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "            else:\n",
    "                print(f\"Image dimensions are too small for resizing: {image_path}\")\n",
    "\n",
    "            # Load the corresponding label (XML file)\n",
    "            xml_filename = os.path.splitext(image_filename)[0] + \".xml\"\n",
    "            xml_path = os.path.join(path_annotations, xml_filename)\n",
    "\n",
    "            # Check if the XML file exists\n",
    "            if os.path.exists(xml_path):\n",
    "                # Parse the XML file to extract the label (you may need to adjust this based on your XML structure)\n",
    "                tree = ET.parse(xml_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                # Initialize a binary mask for this image\n",
    "                mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "                # Find the \"name\" element and check if it exists\n",
    "                name_element = root.find(\"object/name\")\n",
    "                if name_element is not None:\n",
    "                    label = name_element.text  # Use .text to get the text content of the element\n",
    "\n",
    "                    # Check the class label and balance the dataset\n",
    "                    if label == \"APAL\":\n",
    "                        apal_count += 1\n",
    "                    elif label == \"Pseudodiploria\":\n",
    "                        pseudodiploria_count += 1\n",
    "\n",
    "                    # Find the polygon points and draw the mask\n",
    "                    polygon = root.find(\"object/polygon\")\n",
    "                    if polygon is not None:\n",
    "                        points = []\n",
    "                        for pt in polygon.findall(\"pt\"):\n",
    "                            x = int(pt.find(\"x\").text)\n",
    "                            y = int(pt.find(\"y\").text)\n",
    "                            points.append((x, y))\n",
    "                        points = np.array(points, dtype=np.int32)\n",
    "                        cv2.fillPoly(mask, [points], 1)\n",
    "\n",
    "                    # Append the image, label, and mask to the lists\n",
    "                    images.append(image)\n",
    "                    labels.append(label)\n",
    "                    masks.append(mask)\n",
    "\n",
    "                else:\n",
    "                    # Handle the case where the \"name\" element is missing\n",
    "                    print(f\"'name' element not found in XML file: {xml_path}\")\n",
    "            else:\n",
    "                # Handle the case where the XML label file is missing\n",
    "                print(f\"XML label file not found for image: {image_path}\")\n",
    "\n",
    "# Calculate the oversampling and undersampling factors\n",
    "if apal_count < pseudodiploria_count:\n",
    "    oversample_factor = pseudodiploria_count / apal_count\n",
    "    undersample_factor = 1.0\n",
    "else:\n",
    "    oversample_factor = 1.0\n",
    "    undersample_factor = apal_count / pseudodiploria_count\n",
    "\n",
    "# Apply oversampling and undersampling\n",
    "oversample_apal = oversample_apal and apal_count < pseudodiploria_count\n",
    "undersample_pseudodiploria = undersample_pseudodiploria and apal_count > pseudodiploria_count\n",
    "\n",
    "# Initialize lists to store oversampled data\n",
    "oversampled_images = []\n",
    "oversampled_labels = []\n",
    "oversampled_masks = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    if labels[i] == \"APAL\" and oversample_apal:\n",
    "        for _ in range(int(oversample_factor)):\n",
    "            oversampled_images.append(images[i])\n",
    "            oversampled_labels.append(labels[i])\n",
    "            oversampled_masks.append(masks[i])\n",
    "    elif labels[i] == \"Pseudodiploria\" and undersample_pseudodiploria:\n",
    "        if np.random.rand() < 1 / undersample_factor:\n",
    "            continue\n",
    "\n",
    "    oversampled_images.append(images[i])\n",
    "    oversampled_labels.append(labels[i])\n",
    "    oversampled_masks.append(masks[i])\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "images = np.array(oversampled_images)\n",
    "masks = np.array(oversampled_masks)\n",
    "labels = np.array(oversampled_labels)\n",
    "\n",
    "# Now, you have NumPy arrays for images, masks, and labels\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Masks shape: {masks.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Check class distribution\n",
    "unique_labels, class_counts = np.unique(labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, class_counts):\n",
    "    print(f\"Class: {label}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1276, 224, 224, 3)\n",
      "y_train shape: (1276, 224, 224)\n",
      "X_test shape: (319, 224, 224, 3)\n",
      "y_test shape: (319, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save your data to a pickle file\n",
    "with open('../data/external/data_RCNN.pkl', 'wb') as f:\n",
    "    pickle.dump((X_train, y_train, X_test, y_test), f)\n",
    "\n",
    "# Check the shapes\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
